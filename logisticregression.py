# -*- coding: utf-8 -*-
"""LogisticRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NoFAOWyUd1YgeyZItx3sFxJrLHxL9Kd3
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
# %matplotlib inline
from matplotlib import pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

df=pd.read_csv("https://raw.githubusercontent.com/Premalatha-success/Datasets/main/titanic-training-data.csv")

df.head()

df.tail()

df.sample(10)

df.shape

df.dtypes

df.info()

df.describe()

df.isnull().sum()

sns.countplot(x="Survived",data=df)

pd.crosstab(df["Survived"],df["Sex"])

sns.countplot(x="Survived",hue="Sex",data=df)

sns.countplot(x="Survived",hue="Pclass",data=df)

sns.boxplot(x="Pclass",y="Age",data=df)

df.isnull().sum()

df.drop("Cabin",axis=1,inplace=True)

df.head()

df.shape

df.dropna(inplace=True)

df.isnull().sum()

df.shape

df=pd.get_dummies(df,columns=["Sex","Pclass","Embarked"])

df.head()

df=df.drop(["Name","PassengerId","Ticket","Fare"],axis=1)

df.info()

x=df.drop("Survived",axis=1)
y=df["Survived"]

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.30,random_state=1)

model=LogisticRegression()

model.fit(x_train,y_train)

model.score(x_train,y_train)

model.score(x_test,y_test)

predictions=model.predict(x_test)

from sklearn.metrics import accuracy_score
accuracy_score(y_test,predictions)

